{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "project-title"
      },
      "source": [
        "# Flower Recognition Project\n",
        "This notebook trains a ResNet-18 model to classify 5 types of flowers using a Kaggle dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fn2fYg4GjK2b",
        "outputId": "19ef6769-ea3f-4ccf-caff-1ba9a3a22bac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "install-libraries",
        "outputId": "e7f7b9fe-312b-450c-823f-0a38bf73da66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m82.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hLibraries installed successfully!\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: Install required libraries\n",
        "# Install PyTorch, torchvision, and Gradio quietly to avoid cluttering output\n",
        "!pip install torch torchvision gradio -q\n",
        "print('Libraries installed successfully!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mount-drive-and-imports",
        "outputId": "8bc2bb03-31a1-42d6-b9b8-1ba038a3c0ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive mounted and libraries imported!\n"
          ]
        }
      ],
      "source": [
        "# Cell 2: Mount Google Drive and import libraries\n",
        "from google.colab import drive\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import gradio as gr\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "\n",
        "# Define dataset path (UPDATE THIS to your dataset path in Google Drive)\n",
        "dataset_path = '/content/drive/MyDrive/Flowers/flowers'\n",
        "\n",
        "print('Drive mounted and libraries imported!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "preprocess-data",
        "outputId": "5d6c693e-f514-4292-cd16-924ed3a4d30e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: ['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']\n",
            "Number of classes: 5\n",
            "Training samples: 2060, Validation samples: 515\n"
          ]
        }
      ],
      "source": [
        "# Cell 3: Define transformations and load dataset\n",
        "# Transformations for training (with augmentation to prevent overfitting)\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize to 224x224 for ResNet\n",
        "    transforms.RandomHorizontalFlip(),  # Augmentation: random flip\n",
        "    transforms.RandomRotation(15),  # Augmentation: random rotation\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),  # Augmentation: color jitter\n",
        "    transforms.ToTensor(),  # Convert image to tensor\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ImageNet normalization\n",
        "])\n",
        "\n",
        "# Transformations for validation (no augmentation)\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load dataset using ImageFolder\n",
        "dataset = datasets.ImageFolder(root=dataset_path, transform=train_transforms)\n",
        "\n",
        "# Split dataset into training (80%) and validation (20%)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "# Apply validation transforms to validation dataset\n",
        "val_dataset.dataset.transform = val_transforms\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "# Load class names\n",
        "class_names = dataset.classes\n",
        "num_classes = len(class_names)\n",
        "print(f'Classes: {class_names}')\n",
        "print(f'Number of classes: {num_classes}')\n",
        "print(f'Training samples: {train_size}, Validation samples: {val_size}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "setup-model",
        "outputId": "60f07e90-4d51-4e5f-a02c-4a841ad0e664"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 76.3MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model, loss function, optimizer, and scheduler initialized!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Cell 4: Set up ResNet-18 model with dropout\n",
        "# Check for GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')\n",
        "\n",
        "# Define custom ResNet-18 with dropout to prevent overfitting\n",
        "class ResNet18WithDropout(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(ResNet18WithDropout, self).__init__()\n",
        "        self.resnet = torchvision.models.resnet18(pretrained=True)\n",
        "        in_features = self.resnet.fc.in_features\n",
        "        self.resnet.fc = nn.Sequential(\n",
        "            nn.Dropout(0.5),  # Dropout to prevent overfitting\n",
        "            nn.Linear(in_features, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.resnet(x)\n",
        "\n",
        "# Initialize model, loss function, optimizer, and scheduler\n",
        "model = ResNet18WithDropout(num_classes=num_classes).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
        "\n",
        "print('Model, loss function, optimizer, and scheduler initialized!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "train-model",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76fa4649-55b7-4e1e-c901-09a11b8defb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20:\n",
            "Train Loss: 0.8599, Train Acc: 69.66%\n",
            "Val Loss: 1.4087, Val Acc: 67.38%\n",
            "Best model saved!\n",
            "Epoch 2/20:\n",
            "Train Loss: 0.5409, Train Acc: 80.53%\n",
            "Val Loss: 0.8825, Val Acc: 71.84%\n",
            "Best model saved!\n",
            "Epoch 3/20:\n",
            "Train Loss: 0.3922, Train Acc: 86.17%\n",
            "Val Loss: 0.5621, Val Acc: 83.50%\n",
            "Best model saved!\n",
            "Epoch 4/20:\n",
            "Train Loss: 0.4273, Train Acc: 85.24%\n",
            "Val Loss: 0.9440, Val Acc: 73.59%\n",
            "Epoch 5/20:\n",
            "Train Loss: 0.2971, Train Acc: 89.61%\n",
            "Val Loss: 0.4377, Val Acc: 84.08%\n",
            "Best model saved!\n",
            "Epoch 6/20:\n",
            "Train Loss: 0.2132, Train Acc: 91.84%\n",
            "Val Loss: 0.6124, Val Acc: 78.45%\n",
            "Epoch 7/20:\n",
            "Train Loss: 0.1896, Train Acc: 93.50%\n",
            "Val Loss: 0.5794, Val Acc: 82.91%\n",
            "Epoch 8/20:\n",
            "Train Loss: 0.2229, Train Acc: 92.38%\n",
            "Val Loss: 0.6277, Val Acc: 80.00%\n",
            "Epoch 9/20:\n",
            "Train Loss: 0.1279, Train Acc: 95.29%\n",
            "Val Loss: 0.8748, Val Acc: 76.70%\n",
            "Epoch 10/20:\n",
            "Train Loss: 0.0587, Train Acc: 98.11%\n",
            "Val Loss: 0.3768, Val Acc: 88.16%\n",
            "Best model saved!\n",
            "Epoch 11/20:\n",
            "Train Loss: 0.0286, Train Acc: 99.51%\n",
            "Val Loss: 0.3612, Val Acc: 88.16%\n",
            "Best model saved!\n",
            "Epoch 12/20:\n",
            "Train Loss: 0.0148, Train Acc: 99.85%\n",
            "Val Loss: 0.3466, Val Acc: 89.13%\n",
            "Best model saved!\n",
            "Epoch 13/20:\n",
            "Train Loss: 0.0138, Train Acc: 99.61%\n",
            "Val Loss: 0.3574, Val Acc: 87.96%\n",
            "Epoch 14/20:\n",
            "Train Loss: 0.0107, Train Acc: 99.90%\n",
            "Val Loss: 0.3565, Val Acc: 89.71%\n",
            "Epoch 15/20:\n",
            "Train Loss: 0.0108, Train Acc: 99.81%\n",
            "Val Loss: 0.3390, Val Acc: 89.32%\n",
            "Best model saved!\n",
            "Epoch 16/20:\n",
            "Train Loss: 0.0076, Train Acc: 99.95%\n",
            "Val Loss: 0.3675, Val Acc: 87.96%\n",
            "Epoch 17/20:\n",
            "Train Loss: 0.0078, Train Acc: 99.95%\n",
            "Val Loss: 0.3735, Val Acc: 87.96%\n",
            "Epoch 18/20:\n",
            "Train Loss: 0.0057, Train Acc: 100.00%\n",
            "Val Loss: 0.3592, Val Acc: 88.35%\n",
            "Epoch 19/20:\n",
            "Train Loss: 0.0069, Train Acc: 99.90%\n",
            "Val Loss: 0.3764, Val Acc: 88.54%\n",
            "Epoch 20/20:\n",
            "Train Loss: 0.0047, Train Acc: 100.00%\n",
            "Val Loss: 0.3536, Val Acc: 88.74%\n",
            "Early stopping triggered!\n",
            "Training completed!\n"
          ]
        }
      ],
      "source": [
        "# Cell 5: Train the model with early stopping\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=5):\n",
        "    best_val_loss = float('inf')\n",
        "    patience = 5  # Early stopping patience\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        train_correct = 0\n",
        "        train_total = 0\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item() * images.size(0)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            train_total += labels.size(0)\n",
        "            train_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        train_loss = train_loss / train_total\n",
        "        train_acc = 100 * train_correct / train_total\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                val_loss += loss.item() * images.size(0)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                val_total += labels.size(0)\n",
        "                val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        val_loss = val_loss / val_total\n",
        "        val_acc = 100 * val_correct / val_total\n",
        "\n",
        "        # Step the scheduler\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        # Print epoch results\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}:')\n",
        "        print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
        "        print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
        "\n",
        "        # Early stopping\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            patience_counter = 0\n",
        "            torch.save(model.state_dict(), '/content/drive/MyDrive/best_flower_model.pth')\n",
        "            print('Best model saved!')\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= patience:\n",
        "                print('Early stopping triggered!')\n",
        "                break\n",
        "\n",
        "    return model\n",
        "\n",
        "# Train the model\n",
        "model = train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=5)\n",
        "print('Training completed!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "load-best-model",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46edc3dc-c5d8-4c34-b13a-7814000ef343"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model loaded!\n"
          ]
        }
      ],
      "source": [
        "# Cell 6: Load the best model\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/best_flower_model.pth'))\n",
        "model.eval()\n",
        "print('Best model loaded!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "prediction-function",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8c0afa3-0687-4d4f-da1b-b33e350c20ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction function defined!\n"
          ]
        }
      ],
      "source": [
        "# Cell 7: Define prediction function\n",
        "def predict_image(image_path, model, class_names, transform):\n",
        "    model.eval()\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(image)\n",
        "        probabilities = torch.softmax(outputs, dim=1)[0]\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "    predicted_class = class_names[predicted.item()]\n",
        "    confidence = probabilities[predicted.item()].item()\n",
        "    prob_dict = {class_names[i]: prob.item() for i, prob in enumerate(probabilities)}\n",
        "    return predicted_class, confidence, prob_dict\n",
        "\n",
        "print('Prediction function defined!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "gradio-interface",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "outputId": "60116422-123a-4840-b0f2-a22e3ce3fdc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "* To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7861, \"/\", \"100%\", 500, false, window.element)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradio interface launched!\n"
          ]
        }
      ],
      "source": [
        "# Cell 8: Set up and launch Gradio interface\n",
        "def gradio_predict(image):\n",
        "    transform = val_transforms\n",
        "    predicted_class, confidence, prob_dict = predict_image(image, model, class_names, transform)\n",
        "    result = f'Predicted Flower: {predicted_class}\\nConfidence: {confidence:.2%}\\n\\nProbabilities:\\n'\n",
        "    for cls, prob in prob_dict.items():\n",
        "        result += f'{cls}: {prob:.2%}\\n'\n",
        "    return result\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=gradio_predict,\n",
        "    inputs=gr.Image(type='filepath'),\n",
        "    outputs='text',\n",
        "    title='Flower Recognition',\n",
        "    description='Upload an image of a flower to classify it as one of: daisy, dandelion, rose, sunflower, or tulip.'\n",
        ")\n",
        "iface.launch(share=False)\n",
        "print('Gradio interface launched!')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}